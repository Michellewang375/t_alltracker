# -*- coding: utf-8 -*-
"""computing PCA (git).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XpsBGa-wkjBLIxfFTlytZLjpoVqY2Dg0

# Computing the PCA of a Foreground Object
We show in our paper many figures with object parts colored like rainbows. These visualizations are obtained by computing a PCA of patch features on the foreground object. This is what we will compute in this tutorial! Let's start by loading some pre-requisites.

### Setup

Let's start by loading some pre-requisites and checking the DINOv3 repository location:
- `local` if `DINOV3_LOCATION` environment variable was set to work with a local version of DINOv3 repository;
- `github` if the code should be loaded via torch hub.
"""

import pickle
import os
import urllib

import numpy as np
import matplotlib.pyplot as plt
from PIL import Image

import torch
import torchvision.transforms.functional as TF
from sklearn.decomposition import PCA
from scipy import signal
import os, shutil

DINOV3_GITHUB_LOCATION = "facebookresearch/dinov3"

if os.getenv("DINOV3_LOCATION") is not None:
    DINOV3_LOCATION = os.getenv("DINOV3_LOCATION")
else:
    DINOV3_LOCATION = DINOV3_GITHUB_LOCATION

print(f"DINOv3 location set to {DINOV3_LOCATION}")


#------------------------------------------------------------------------------------------------------------------

# loading in .pth file
base_dir = os.path.dirname(__file__)
model_path = os.path.join(base_dir, 'dinov3_vits16_pretrain_lvd1689m-08c60483.pth')

model = torch.load(model_path, map_location='cpu')

#------------------------------------------------------------------------------------------------------------------

# Make the checkpoints folder if it doesn't exist
os.makedirs(os.path.expanduser("~/.cache/torch/hub/checkpoints"), exist_ok=True)

# Move the uploaded file to that folder
shutil.move(
    "dinov3_vits16_pretrain_lvd1689m-08c60483.pth",
    os.path.expanduser("~/.cache/torch/hub/checkpoints/dinov3_vits16_pretrain_lvd1689m-08c60483.pth")
)


"""### Model Loading
We load the DINOv3 ViT-L model. Feel free to try other DINOv3 models as well!
"""

# examples of available DINOv3 models:
MODEL_DINOV3_VITS = "dinov3_vits16"
MODEL_DINOV3_VITSP = "dinov3_vits16plus"
MODEL_DINOV3_VITB = "dinov3_vitb16"
MODEL_DINOV3_VITL = "dinov3_vitl16"
MODEL_DINOV3_VITHP = "dinov3_vith16plus"
MODEL_DINOV3_VIT7B = "dinov3_vit7b16"

MODEL_NAME = MODEL_DINOV3_VITS

model = torch.hub.load(
    repo_or_dir=DINOV3_LOCATION,
    model=MODEL_NAME,
    source="local" if DINOV3_LOCATION != DINOV3_GITHUB_LOCATION else "github",
)
# model.cuda() # Removed this line to run on CPU

"""### Loading the Foreground Classifier from the Other Tutorial
For this tutorial, we use the classifier trained in the `foreground_segmentation` notebook. If you haven't already, have a look! Once you have trained your foreground / background classifier on patch features, you should be able to load it here.
"""

from google.colab import files

# Upload your downloaded .pth file from your local machine
uploaded = files.upload()

save_root = '.'
model_path = os.path.join(save_root, "fg_classifier.pkl")
with open(model_path, 'rb') as file:
    clf = pickle.load(file)

"""### Loading an Image and Applying the Right Transform
Let's load an image and process it in order to make it a multiple of the patch size.
"""

# PATCH_SIZE = 16
# IMAGE_SIZE = 768

# IMAGENET_MEAN = (0.485, 0.456, 0.406)
# IMAGENET_STD = (0.229, 0.224, 0.225)

# image_uri = "https://dl.fbaipublicfiles.com/dinov3/notebooks/pca/test_image.jpg"

# def load_image_from_url(url: str) -> Image:
#     with urllib.request.urlopen(url) as f:
#         return Image.open(f).convert("RGB")

# # image resize transform to dimensions divisible by patch size
# def resize_transform(
#     mask_image: Image,
#     image_size: int = IMAGE_SIZE,
#     patch_size: int = PATCH_SIZE,
# ) -> torch.Tensor:
#     w, h = mask_image.size
#     h_patches = int(image_size / patch_size)
#     w_patches = int((w * image_size) / (h * patch_size))
#     return TF.to_tenso